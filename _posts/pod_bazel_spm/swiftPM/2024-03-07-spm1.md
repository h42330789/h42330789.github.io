---
title: Swift Package Manage使用及自定义
author: 独孤流
date: 2024-03-07 01:04:00 +0800
categories: [Pod_bazel_spm, SPM]
tags: [SPM, SwiftPM]     # TAG names should always be lowercase
---

参考：
- [Swift Package Manager 使用](https://juejin.cn/post/6871489791213436941)
- [iOS包依赖管理工具（五）：Swift Package Manager（SPM）自定义篇](https://www.jianshu.com/p/420d00b0bdca)
- [SwiftUI中文入门](https://goswiftui.com/swiftui-tutoria/)
- [SwiftUI_learning01](https://github.com/jasonyen1009/SwiftUI_learning01)
- [swiftui-state-property-binding-stateobject-observedobject-environmentobject-學習筆記](https://medium.com/%E5%BD%BC%E5%BE%97%E6%BD%98%E7%9A%84-swift-ios-app-%E9%96%8B%E7%99%BC%E6%95%99%E5%AE%A4/swiftui-state-property-binding-stateobject-observedobject-environmentobject-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98-b4366f87f4f4)

> ### 前言
> 最近在接入亚马逊人脸识别时，亚马逊提供的最新SDK是使用`Swift Package Manage`管理的，而项目里使用的其他三方SDK是使用`cocoa pods`进行管理，一开始以为两个不能兼容，但是经过实际测试，是可以正常一起使用

### 普通项目或Pod项目中引入`Swift Package Manager`管理的项目

以接入`amplify-swift`
git地址：`https://github.com/aws-amplify/amplify-swift`

以接入`amplify-ui-swift-liveness`
git地址：`https://github.com/aws-amplify/amplify-ui-swift-liveness`

![image](/assets/img/pod/spm1-01.png)
![image](/assets/img/pod/spm1-02.png)
![image](/assets/img/pod/spm1-03.png)
![image](/assets/img/pod/spm1-04.png)

----
### `UIKit`里引入`SwiftUI`框架
> 由于引入的`AmplifyUILiveness`是使用的`SwiftUI`，我们的主题项目使用的是标准UIKit，所以需要再普通页面引入需要进行包装一成

参考：
- [SwiftUI 与 UIKit 混合开发](https://coderjtao.github.io/2020/08/30/SwiftUI-%E4%B8%8E-UIKit-%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/)
使用`UIHostingController`进行包装
```
import UIKit
import SwiftUI
class ViewController: UIViewController {
    override func viewDidLoad() {
        super.viewDidLoad()
        let btn = UIButton(frame: CGRect(x: 100, y: 100, width: 60, height: 40))
        btn.setTitle("showTest", for: .normal)
        btn.setTitleColor(.black, for: .normal)
        btn.addTarget(self, action: #selector(showMyTestSwiftUI), for: .touchUpInside)
        self.view.addSubview(btn)
    }
    
    @objc func showMyTestSwiftUI() {
        let vc = UIHostingController(rootView: Text("Text"))
        self.navigationController?.pushViewController(vc, animated: true)
    }
}
```
----
### 自定义`Swift Package Manager`管理的项目
> 由于我们的主项目需要支持到`iOS12`，但`SwiftUI`最低需要`iOS14`,所以需要把`AmplifyUILiveness`下载好源码改成普通UIKit的框架

本地调试SPM项目：
参考：[iOS包依赖管理工具（五）：Swift Package Manager（SPM）自定义篇](https://www.jianshu.com/p/420d00b0bdca)


核心操作：FaceLivenessDetectionViewModel
等待页面：GetReadyPageView -> CameraPreviewView -> previewCaptureSession?.startSession
开始 FaceLivenessDetectorView -> onBegin -> displayState = .displayingLiveness -> _FaceLivenessDetectionView
人脸扫描页面：
_FaceLivenessDetectionView -> makeUIViewController -> _LivenessViewController -> viewDidAppear -> setupAVLayer
-> viewModel.startCamera -> captureSession.startSession ->  videoOutput.setSampleBufferDelegate 
-> 系统delegate回调 -> captureOutput -> FaceDetectorShortRange.detectFaces -> prediction(人脸数) -> detectionResultHandler?.process -> .singleFace -> 
一个人脸且符合要求的人脸 -> 初始化配置 -> initializeLivenessStream -> livenessService?.initializeLivenessStream -> 链接aws服务器 -> websocket.open(url: xx)
有新视频流后：
detectionResultHandler?.process -> .recording -> drawOval -> sendInitialFaceDetectedEvent


摄像头准备好后开始初始化Stream
FaceLivenessDetectorView.init -> LivenessCaptureSession -> OutputSampleBufferCapturer -> FaceLivenessDetectionViewModel
OutputSampleBufferCapturer -> faceDetector.detectFaces -> detectionResultHandler?.process
FaceLivenessDetectionViewModel -> FaceDetectionResultHandler -> process -> initializeLivenessStream